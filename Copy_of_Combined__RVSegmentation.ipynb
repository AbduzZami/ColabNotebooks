{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12196859,
          "sourceType": "datasetVersion",
          "datasetId": 7604236
        },
        {
          "sourceId": 12974591,
          "sourceType": "datasetVersion",
          "datasetId": 8211951
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbduzZami/ColabNotebooks/blob/main/Copy_of_Combined__RVSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "shadmansobhan_combined_dataset_pt1_path = kagglehub.dataset_download('shadmansobhan/combined-dataset-pt1')\n",
        "shadmansobhan_dataset_mp_review_path = kagglehub.dataset_download('shadmansobhan/dataset-mp-review')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJuMLy8iZERq",
        "outputId": "5ad8bf81-ad7e-4f1f-cf3d-70b7deffa3c0"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/shadmansobhan/combined-dataset-pt1?dataset_version_number=5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.46G/3.46G [02:53<00:00, 21.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'dataset-mp-review' dataset.\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER_NAME='densenet121'\n",
        "NUM_CLASS_SEG=2\n",
        "NUM_CLASS_CLS=2\n",
        "MODE=1\n",
        "DATASET_NAME='Combined_GI_Tract' #Combined_RBV Combined_GI_Tract"
      ],
      "metadata": {
        "id": "2NS7XH4zODLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8u5OM8QbLDx",
        "outputId": "78a77c16-63b3-4a9a-c096-0562e16c8171"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard libraries\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "import time\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Image processing\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchinfo import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# Torchvision\n",
        "from torchvision.models.efficientnet import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from torchvision.models import (\n",
        "    resnet50, ResNet50_Weights,\n",
        "    densenet121, DenseNet121_Weights,\n",
        "    mobilenet_v2, MobileNet_V2_Weights,\n",
        "    mobilenet_v3_large, MobileNet_V3_Large_Weights,\n",
        "    inception_v3, Inception_V3_Weights,\n",
        "    efficientnet_b0, EfficientNet_B0_Weights,\n",
        "    efficientnet_b1, EfficientNet_B1_Weights\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Albumentations\n",
        "import albumentations as album\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Set device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:46:28.384852Z",
          "iopub.execute_input": "2025-09-06T07:46:28.385501Z",
          "iopub.status.idle": "2025-09-06T07:46:38.127458Z",
          "shell.execute_reply.started": "2025-09-06T07:46:28.385468Z",
          "shell.execute_reply": "2025-09-06T07:46:38.12679Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iEdp1bmZERs",
        "outputId": "325827c7-6d64-43ce-8b45-f419ece6e399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Define"
      ],
      "metadata": {
        "id": "lK1rJt1tZERt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # SeparableConv2d remains unchanged\n",
        "# class SeparableConv2d(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1, bias=False):\n",
        "#         super().__init__()\n",
        "#         self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels, bias=bias)\n",
        "#         self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.pointwise(self.depthwise(x))\n",
        "\n",
        "# # ASPP remains unchanged\n",
        "# class ASPP(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels, atrous_rates):\n",
        "#         super().__init__()\n",
        "#         modules = [\n",
        "#             nn.Sequential(\n",
        "#                 nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
        "#                 nn.BatchNorm2d(out_channels),\n",
        "#                 nn.ReLU(inplace=True)\n",
        "#             )\n",
        "#         ]\n",
        "#         for rate in atrous_rates:\n",
        "#             modules.append(nn.Sequential(\n",
        "#                 SeparableConv2d(in_channels, out_channels, 3, padding=rate, dilation=rate, bias=False),\n",
        "#                 nn.BatchNorm2d(out_channels),\n",
        "#                 nn.ReLU(inplace=True)\n",
        "#             ))\n",
        "#         modules.append(nn.Sequential(\n",
        "#             nn.AdaptiveAvgPool2d(1),\n",
        "#             nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "#             nn.BatchNorm2d(out_channels),\n",
        "#             nn.ReLU(inplace=True)\n",
        "#         ))\n",
        "#         self.convs = nn.ModuleList(modules)\n",
        "#         self.project = nn.Sequential(\n",
        "#             nn.Conv2d((len(atrous_rates) + 2) * out_channels, out_channels, 1, bias=False),\n",
        "#             nn.BatchNorm2d(out_channels),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Dropout2d(0.5)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         size = x.shape[2:]\n",
        "#         res = [F.interpolate(conv(x), size=size, mode='bilinear', align_corners=True) if i == len(self.convs)-1 else conv(x) for i, conv in enumerate(self.convs)]\n",
        "#         return self.project(torch.cat(res, dim=1))\n",
        "\n",
        "# # MFF Block\n",
        "# class MFFBlock(nn.Module):\n",
        "#     def __init__(self, in_channels_low, in_channels_high, out_channels):\n",
        "#         super().__init__()\n",
        "#         self.low_proj = nn.Conv2d(in_channels_low, out_channels, 1, bias=False)\n",
        "#         self.high_proj = nn.Conv2d(in_channels_high, out_channels, 1, bias=False)\n",
        "#         self.fusion = nn.Sequential(\n",
        "#             nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
        "#             nn.BatchNorm2d(out_channels),\n",
        "#             nn.ReLU(inplace=True)\n",
        "#         )\n",
        "#         self.se = nn.Sequential(\n",
        "#             nn.AdaptiveAvgPool2d(1),\n",
        "#             nn.Conv2d(out_channels, out_channels // 8, 1),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Conv2d(out_channels // 8, out_channels, 1),\n",
        "#             nn.Sigmoid()\n",
        "#         )\n",
        "\n",
        "#     def forward(self, low_feat, high_feat):\n",
        "#         high_feat = F.interpolate(high_feat, size=low_feat.shape[2:], mode='bilinear', align_corners=True)\n",
        "#         low_feat = self.low_proj(low_feat)\n",
        "#         high_feat = self.high_proj(high_feat)\n",
        "#         x = low_feat + high_feat\n",
        "#         x = self.fusion(x)\n",
        "#         return x * self.se(x)\n",
        "\n",
        "# # CAFSE Block\n",
        "# class CAFSEBlock(nn.Module):\n",
        "#     def __init__(self, channels):\n",
        "#         super().__init__()\n",
        "#         self.coarse = nn.Sequential(\n",
        "#             nn.Conv2d(channels, channels, 3, padding=1),\n",
        "#             nn.BatchNorm2d(channels),\n",
        "#             nn.ReLU(inplace=True)\n",
        "#         )\n",
        "#         self.fine = nn.Sequential(\n",
        "#             nn.Conv2d(channels, channels, 1),\n",
        "#             nn.BatchNorm2d(channels),\n",
        "#             nn.Sigmoid()\n",
        "#         )\n",
        "\n",
        "#     def forward(self, decoder_feat, aspp_feat):\n",
        "#         aspp_feat = F.interpolate(aspp_feat, size=decoder_feat.shape[2:], mode='bilinear', align_corners=True)\n",
        "#         coarse = self.coarse(aspp_feat)\n",
        "#         fine = self.fine(decoder_feat)\n",
        "#         return decoder_feat + coarse * fine\n",
        "\n",
        "# # Decoder remains unchanged\n",
        "# class Decoder(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels, 48, 1, bias=False),\n",
        "#             nn.BatchNorm2d(48),\n",
        "#             nn.ReLU(inplace=True)\n",
        "#         )\n",
        "#         self.fuse = nn.Sequential(\n",
        "#             SeparableConv2d(96, out_channels, 3, padding=1, bias=False),\n",
        "#             nn.BatchNorm2d(out_channels),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             SeparableConv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
        "#             nn.BatchNorm2d(out_channels),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Dropout2d(0.3)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x, low_level_feat):\n",
        "#         x = F.interpolate(x, size=low_level_feat.shape[2:], mode='bilinear', align_corners=True)\n",
        "#         x = self.conv1(x)\n",
        "#         x = torch.cat([x, low_level_feat], dim=1)\n",
        "#         return self.fuse(x)\n",
        "\n",
        "# #Main model\n",
        "# class DeepLabV3Plus(nn.Module):\n",
        "#     def __init__(self, num_num_classes_seg_seg=1, num_num_classes_seg_cls=2, mode=1, output_stride=16, activation='sigmoid'):\n",
        "#         super().__init__()\n",
        "#         self.mode = mode\n",
        "#         self.output_stride = output_stride\n",
        "\n",
        "#         # backbone = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "#         # backbone = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "#         # backbone = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "#         backbone = densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1)\n",
        "#         # backbone = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)\n",
        "#         # backbone = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n",
        "#         # backbone = inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1)\n",
        "#         # backbone = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "#         # backbone = efficientnet_b1(weights=EfficientNet_B1_Weights.IMAGENET1K_V1)\n",
        "\n",
        "#         features = list(backbone.features.children())\n",
        "#         if output_stride == 16:\n",
        "#             self.low_level = nn.Sequential(*features[:3])\n",
        "#             self.high_level = nn.Sequential(*features[3:])\n",
        "#         else:\n",
        "#             self.low_level = nn.Sequential(*features[:2])\n",
        "#             self.high_level = nn.Sequential(*features[2:])\n",
        "\n",
        "#         low_level_channels = 24 if output_stride == 16 else 16\n",
        "#         self.low_proj = nn.Sequential(\n",
        "#             nn.Conv2d(low_level_channels, 48, 1, bias=False),\n",
        "#             nn.BatchNorm2d(48),\n",
        "#             nn.ReLU(inplace=True)\n",
        "#         )\n",
        "\n",
        "#         atrous_rates = [6, 12, 18] if output_stride == 16 else [12, 24, 36]\n",
        "#         self.aspp = ASPP(1280, 256, atrous_rates)\n",
        "#         self.mff = MFFBlock(48, 256, 256)\n",
        "#         self.decoder = Decoder(256, 256)\n",
        "#         self.cafse = CAFSEBlock(256)\n",
        "#         self.final_conv = nn.Conv2d(256, num_num_classes_seg_seg, 1)\n",
        "\n",
        "#         self.classifier = nn.Sequential(\n",
        "#             nn.AdaptiveAvgPool2d(1),\n",
        "#             nn.Flatten(),\n",
        "#             nn.Linear(1280, 512),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(512, num_num_classes_seg_cls)\n",
        "#         )\n",
        "\n",
        "#         if activation == 'sigmoid':\n",
        "#             self.activation = nn.Sigmoid()\n",
        "#         elif activation == 'softmax2d':\n",
        "#             self.activation = nn.Softmax2d()\n",
        "#         else:\n",
        "#             self.activation = None\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         input_size = x.size()[2:]\n",
        "#         low_feat = self.low_level(x)\n",
        "#         high_feat = self.high_level(low_feat)\n",
        "#         low_proj = self.low_proj(low_feat)\n",
        "\n",
        "#         if self.mode == 0:\n",
        "#             out = self.classifier(high_feat)\n",
        "#             return out\n",
        "#         elif self.mode == 1:\n",
        "#             aspp_out = self.aspp(high_feat)\n",
        "#             mff_out = self.mff(low_proj, aspp_out)\n",
        "#             decoder_out = self.decoder(mff_out, low_proj)\n",
        "#             cafse_out = self.cafse(decoder_out, aspp_out)\n",
        "#             out = self.final_conv(cafse_out)\n",
        "#             out = F.interpolate(out, size=input_size, mode='bilinear', align_corners=True)\n",
        "#             if self.activation is not None:\n",
        "#                 out = self.activation(out)\n",
        "#             return out\n",
        "#         else:\n",
        "#             raise ValueError(\"Mode must be 0 (classification) or 1 (segmentation)\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:46:38.128849Z",
          "iopub.execute_input": "2025-09-06T07:46:38.129819Z",
          "iopub.status.idle": "2025-09-06T07:46:38.13646Z",
          "shell.execute_reply.started": "2025-09-06T07:46:38.129785Z",
          "shell.execute_reply": "2025-09-06T07:46:38.135762Z"
        },
        "id": "Fg_IuO43ZERu"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import (\n",
        "    efficientnet_b0, EfficientNet_B0_Weights,\n",
        "    efficientnet_b1, EfficientNet_B1_Weights,\n",
        "    resnet50, ResNet50_Weights,\n",
        "    densenet121, DenseNet121_Weights,\n",
        "    mobilenet_v2, MobileNet_V2_Weights,\n",
        "    mobilenet_v3_large, MobileNet_V3_Large_Weights,\n",
        "    inception_v3, Inception_V3_Weights\n",
        ")\n",
        "\n",
        "# SeparableConv2d remains unchanged\n",
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1, bias=False):\n",
        "        super().__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels, bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pointwise(self.depthwise(x))\n",
        "\n",
        "# ASPP remains unchanged\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, atrous_rates):\n",
        "        super().__init__()\n",
        "        modules = [\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        ]\n",
        "        for rate in atrous_rates:\n",
        "            modules.append(nn.Sequential(\n",
        "                SeparableConv2d(in_channels, out_channels, 3, padding=rate, dilation=rate, bias=False),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ))\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ))\n",
        "        self.convs = nn.ModuleList(modules)\n",
        "        self.project = nn.Sequential(\n",
        "            nn.Conv2d((len(atrous_rates) + 2) * out_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.5)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        size = x.shape[2:]\n",
        "        res = [F.interpolate(conv(x), size=size, mode='bilinear', align_corners=True) if i == len(self.convs)-1 else conv(x) for i, conv in enumerate(self.convs)]\n",
        "        return self.project(torch.cat(res, dim=1))\n",
        "\n",
        "# MFFBlock remains unchanged\n",
        "class MFFBlock(nn.Module):\n",
        "    def __init__(self, in_channels_low, in_channels_high, out_channels):\n",
        "        super().__init__()\n",
        "        self.low_proj = nn.Conv2d(in_channels_low, out_channels, 1, bias=False)\n",
        "        self.high_proj = nn.Conv2d(in_channels_high, out_channels, 1, bias=False)\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.se = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(out_channels, out_channels // 8, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels // 8, out_channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, low_feat, high_feat):\n",
        "        high_feat = F.interpolate(high_feat, size=low_feat.shape[2:], mode='bilinear', align_corners=True)\n",
        "        low_feat = self.low_proj(low_feat)\n",
        "        high_feat = self.high_proj(high_feat)\n",
        "        x = low_feat + high_feat\n",
        "        x = self.fusion(x)\n",
        "        return x * self.se(x)\n",
        "\n",
        "# CAFSEBlock remains unchanged\n",
        "class CAFSEBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.coarse = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.fine = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, decoder_feat, aspp_feat):\n",
        "        aspp_feat = F.interpolate(aspp_feat, size=decoder_feat.shape[2:], mode='bilinear', align_corners=True)\n",
        "        coarse = self.coarse(aspp_feat)\n",
        "        fine = self.fine(decoder_feat)\n",
        "        return decoder_feat + coarse * fine\n",
        "\n",
        "# Decoder remains unchanged\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 48, 1, bias=False),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.fuse = nn.Sequential(\n",
        "            SeparableConv2d(96, out_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            SeparableConv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, low_level_feat):\n",
        "        x = F.interpolate(x, size=low_level_feat.shape[2:], mode='bilinear', align_corners=True)\n",
        "        x = self.conv1(x)\n",
        "        x = torch.cat([x, low_level_feat], dim=1)\n",
        "        return self.fuse(x)\n",
        "\n",
        "# Main model with support for multiple backbones\n",
        "class DeepLabV3Plus(nn.Module):\n",
        "    def __init__(self, backbone_name='densenet121', num_num_classes_seg_seg=1, num_num_classes_seg_cls=2, mode=1, output_stride=16, activation='sigmoid'):\n",
        "        super().__init__()\n",
        "        self.mode = mode\n",
        "        self.output_stride = output_stride\n",
        "\n",
        "        # Backbone configurations\n",
        "        backbone_configs = {\n",
        "            'efficientnet_b0': {\n",
        "                'model': efficientnet_b0,\n",
        "                'weights': EfficientNet_B0_Weights.IMAGENET1K_V1,\n",
        "                'low_level_channels': {'16': 24, '8': 16},\n",
        "                'high_level_channels': 1280,\n",
        "                'split_idx': {'16': 3, '8': 2}\n",
        "            },\n",
        "            'efficientnet_b1': {\n",
        "                'model': efficientnet_b1,\n",
        "                'weights': EfficientNet_B1_Weights.IMAGENET1K_V1,\n",
        "                'low_level_channels': {'16': 24, '8': 16},\n",
        "                'high_level_channels': 1280,\n",
        "                'split_idx': {'16': 3, '8': 2}\n",
        "            },\n",
        "            'resnet50': {\n",
        "                'model': resnet50,\n",
        "                'weights': ResNet50_Weights.IMAGENET1K_V1,\n",
        "                'low_level_channels': {'16': 256, '8': 128},\n",
        "                'high_level_channels': 2048,\n",
        "                'split_idx': {'16': 2, '8': 1}\n",
        "            },\n",
        "            'densenet121': {\n",
        "                'model': densenet121,\n",
        "                'weights': DenseNet121_Weights.IMAGENET1K_V1,\n",
        "                'low_level_channels': {'16': 128, '8': 64},\n",
        "                'high_level_channels': 1024,\n",
        "                'split_idx': {'16': 3, '8': 2}\n",
        "            },\n",
        "            'mobilenet_v2': {\n",
        "                'model': mobilenet_v2,\n",
        "                'weights': MobileNet_V2_Weights.IMAGENET1K_V1,\n",
        "                'low_level_channels': {'16': 24, '8': 16},\n",
        "                'high_level_channels': 1280,\n",
        "                'split_idx': {'16': 4, '8': 3}\n",
        "            },\n",
        "            'mobilenet_v3_large': {\n",
        "                'model': mobilenet_v3_large,\n",
        "                'weights': MobileNet_V3_Large_Weights.IMAGENET1K_V1,\n",
        "                'low_level_channels': {'16': 24, '8': 16},\n",
        "                'high_level_channels': 960,\n",
        "                'split_idx': {'16': 4, '8': 3}\n",
        "            },\n",
        "            'inception_v3': {\n",
        "                'model': lambda **kwargs: inception_v3(**kwargs, aux_logits=False),\n",
        "                'weights': Inception_V3_Weights.IMAGENET1K_V1,\n",
        "                'low_level_channels': {'16': 192, '8': 64},\n",
        "                'high_level_channels': 2048,\n",
        "                'split_idx': {'16': 4, '8': 3}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if backbone_name not in backbone_configs:\n",
        "            raise ValueError(f\"Unsupported backbone: {backbone_name}\")\n",
        "\n",
        "        config = backbone_configs[backbone_name]\n",
        "        backbone = config['model'](weights=config['weights'])\n",
        "        features = list(backbone.features.children()) if hasattr(backbone, 'features') else list(backbone.children())[:-2]  # Exclude classifier layers\n",
        "        split_idx = config['split_idx'][str(output_stride)]\n",
        "        self.low_level = nn.Sequential(*features[:split_idx])\n",
        "        self.high_level = nn.Sequential(*features[split_idx:])\n",
        "        low_level_channels = config['low_level_channels'][str(output_stride)]\n",
        "        high_level_channels = config['high_level_channels']\n",
        "\n",
        "        self.low_proj = nn.Sequential(\n",
        "            nn.Conv2d(low_level_channels, 48, 1, bias=False),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        atrous_rates = [6, 12, 18] if output_stride == 16 else [12, 24, 36]\n",
        "        self.aspp = ASPP(high_level_channels, 256, atrous_rates)\n",
        "        self.mff = MFFBlock(48, 256, 256)\n",
        "        self.decoder = Decoder(256, 256)\n",
        "        self.cafse = CAFSEBlock(256)\n",
        "        self.final_conv = nn.Conv2d(256, num_num_classes_seg_seg, 1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(high_level_channels, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_num_classes_seg_cls)\n",
        "        )\n",
        "\n",
        "        if activation == 'sigmoid':\n",
        "            self.activation = nn.Sigmoid()\n",
        "        elif activation == 'softmax2d':\n",
        "            self.activation = nn.Softmax2d()\n",
        "        else:\n",
        "            self.activation = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        input_size = x.size()[2:]\n",
        "        low_feat = self.low_level(x)\n",
        "        high_feat = self.high_level(low_feat)\n",
        "        low_proj = self.low_proj(low_feat)\n",
        "\n",
        "        if self.mode == 0:\n",
        "            out = self.classifier(high_feat)\n",
        "            return out\n",
        "        elif self.mode == 1:\n",
        "            aspp_out = self.aspp(high_feat)\n",
        "            mff_out = self.mff(low_proj, aspp_out)\n",
        "            decoder_out = self.decoder(mff_out, low_proj)\n",
        "            cafse_out = self.cafse(decoder_out, aspp_out)\n",
        "            out = self.final_conv(cafse_out)\n",
        "            out = F.interpolate(out, size=input_size, mode='bilinear', align_corners=True)\n",
        "            if self.activation is not None:\n",
        "                out = self.activation(out)\n",
        "            return out\n",
        "        else:\n",
        "            raise ValueError(\"Mode must be 0 (classification) or 1 (segmentation)\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:46:38.13734Z",
          "iopub.execute_input": "2025-09-06T07:46:38.138251Z",
          "iopub.status.idle": "2025-09-06T07:46:38.167289Z",
          "shell.execute_reply.started": "2025-09-06T07:46:38.138225Z",
          "shell.execute_reply": "2025-09-06T07:46:38.166634Z"
        },
        "id": "kQ5nz9InZERu"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Instantiate your model (segmentation mode)\n",
        "model = DeepLabV3Plus(backbone_name='densenet121', mode=1)\n",
        "\n",
        "# Function to count parameters\n",
        "def count_parameters(module):\n",
        "    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "\n",
        "# Count for each key module\n",
        "print(\"Trainable parameters breakdown:\")\n",
        "print(f\"Backbone (EfficientNet): {count_parameters(model.low_level) + count_parameters(model.high_level):,}\")\n",
        "print(f\"ASPP:                    {count_parameters(model.aspp):,}\")\n",
        "print(f\"MFF Block:               {count_parameters(model.mff):,}\")\n",
        "print(f\"Decoder:                 {count_parameters(model.decoder):,}\")\n",
        "print(f\"CAFSE Block:             {count_parameters(model.cafse):,}\")\n",
        "print(f\"Final Conv (Seg Output): {count_parameters(model.final_conv):,}\")\n",
        "print(f\"Classifier Head:         {count_parameters(model.classifier):,}\")\n",
        "\n",
        "# Total\n",
        "total = count_parameters(model)\n",
        "print(f\"\\nTotal Trainable Parameters: {total:,}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:46:38.168678Z",
          "iopub.execute_input": "2025-09-06T07:46:38.168915Z",
          "iopub.status.idle": "2025-09-06T07:46:38.809571Z",
          "shell.execute_reply.started": "2025-09-06T07:46:38.168897Z",
          "shell.execute_reply": "2025-09-06T07:46:38.808793Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFCIYDbWZERv",
        "outputId": "113aedcf-07f9-4e42-cb6b-98fd3ce629d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 130MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters breakdown:\n",
            "Backbone (EfficientNet): 6,953,856\n",
            "ASPP:                    1,669,120\n",
            "MFF Block:               684,832\n",
            "Decoder:                 106,688\n",
            "CAFSE Block:             656,896\n",
            "Final Conv (Seg Output): 257\n",
            "Classifier Head:         525,826\n",
            "\n",
            "Total Trainable Parameters: 10,603,715\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Compile"
      ],
      "metadata": {
        "id": "Acdno7OwZERv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "\n",
        "# SeparableConv2d\n",
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1, bias=False):\n",
        "        super().__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels, bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pointwise(self.depthwise(x))\n",
        "\n",
        "# ASPP\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, atrous_rates):\n",
        "        super().__init__()\n",
        "        modules = [\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        ]\n",
        "        for rate in atrous_rates:\n",
        "            modules.append(nn.Sequential(\n",
        "                SeparableConv2d(in_channels, out_channels, 3, padding=rate, dilation=rate, bias=False),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ))\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ))\n",
        "        self.convs = nn.ModuleList(modules)\n",
        "        self.project = nn.Sequential(\n",
        "            nn.Conv2d((len(atrous_rates) + 2) * out_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.5)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"ASPP input shape: {x.shape}\")\n",
        "        size = x.shape[2:]\n",
        "        res = [F.interpolate(conv(x), size=size, mode='bilinear', align_corners=True) if i == len(self.convs)-1 else conv(x) for i, conv in enumerate(self.convs)]\n",
        "        concatenated = torch.cat(res, dim=1)\n",
        "        print(f\"ASPP concatenated shape: {concatenated.shape}\")\n",
        "        return self.project(concatenated)\n",
        "\n",
        "# MFFBlock\n",
        "class MFFBlock(nn.Module):\n",
        "    def __init__(self, in_channels_low, in_channels_high, out_channels):\n",
        "        super().__init__()\n",
        "        self.low_proj = nn.Conv2d(in_channels_low, out_channels, 1, bias=False)\n",
        "        self.high_proj = nn.Conv2d(in_channels_high, out_channels, 1, bias=False)\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.se = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(out_channels, out_channels // 8, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels // 8, out_channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, low_feat, high_feat):\n",
        "        print(f\"MFFBlock low_feat shape: {low_feat.shape}\")\n",
        "        print(f\"MFFBlock high_feat shape: {high_feat.shape}\")\n",
        "        high_feat = F.interpolate(high_feat, size=low_feat.shape[2:], mode='bilinear', align_corners=True)\n",
        "        low_feat = self.low_proj(low_feat)\n",
        "        high_feat = self.high_proj(high_feat)\n",
        "        x = low_feat + high_feat\n",
        "        x = self.fusion(x)\n",
        "        return x * self.se(x)\n",
        "\n",
        "# CAFSEBlock\n",
        "class CAFSEBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.coarse = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.fine = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, decoder_feat, aspp_feat):\n",
        "        print(f\"CAFSEBlock decoder_feat shape: {decoder_feat.shape}\")\n",
        "        print(f\"CAFSEBlock aspp_feat shape: {aspp_feat.shape}\")\n",
        "        aspp_feat = F.interpolate(aspp_feat, size=decoder_feat.shape[2:], mode='bilinear', align_corners=True)\n",
        "        coarse = self.coarse(aspp_feat)\n",
        "        fine = self.fine(decoder_feat)\n",
        "        return decoder_feat + coarse * fine\n",
        "\n",
        "# Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 48, 1, bias=False),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.fuse = nn.Sequential(\n",
        "            SeparableConv2d(96, out_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            SeparableConv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, low_level_feat):\n",
        "        print(f\"Decoder input x shape: {x.shape}\")\n",
        "        print(f\"Decoder low_level_feat shape: {low_level_feat.shape}\")\n",
        "        x = F.interpolate(x, size=low_level_feat.shape[2:], mode='bilinear', align_corners=True)\n",
        "        x = self.conv1(x)\n",
        "        x = torch.cat([x, low_level_feat], dim=1)\n",
        "        return self.fuse(x)\n",
        "\n",
        "# DeepLabV3Plus\n",
        "class DeepLabV3Plus(nn.Module):\n",
        "    def __init__(self, encoder_name='resnet50', bridge='ASPP', num_classes_seg=2, num_classes_cls=2, mode=1, output_stride=16):\n",
        "        super().__init__()\n",
        "        self.encoder_name = encoder_name\n",
        "        self.bridge = bridge\n",
        "        self.mode = mode\n",
        "        self.output_stride = output_stride\n",
        "\n",
        "        # Encoder configuration\n",
        "        self.encoder_config = {\n",
        "            'resnet18': {'low_level_layer': 'layer1', 'high_level_layer': 'layer4',\n",
        "                         'low_level_channels': 64, 'high_level_channels': 512, 'stride_adjustable': True},\n",
        "            'resnet34': {'low_level_layer': 'layer1', 'high_level_layer': 'layer4',\n",
        "                         'low_level_channels': 64, 'high_level_channels': 512, 'stride_adjustable': True},\n",
        "            'resnet50': {'low_level_layer': 'layer1', 'high_level_layer': 'layer4',\n",
        "                         'low_level_channels': 256, 'high_level_channels': 2048, 'stride_adjustable': True},\n",
        "            'resnet101': {'low_level_layer': 'layer1', 'high_level_layer': 'layer4',\n",
        "                          'low_level_channels': 256, 'high_level_channels': 2048, 'stride_adjustable': True},\n",
        "            'resnet152': {'low_level_layer': 'layer1', 'high_level_layer': 'layer4',\n",
        "                          'low_level_channels': 256, 'high_level_channels': 2048, 'stride_adjustable': True},\n",
        "            'densenet121': {'low_level_layer': 'features.transition1', 'high_level_layer': 'features',\n",
        "                            'low_level_channels': 128, 'high_level_channels': 1024, 'stride_adjustable': False},\n",
        "            'densenet169': {'low_level_layer': 'features.transition1', 'high_level_layer': 'features',\n",
        "                            'low_level_channels': 128, 'high_level_channels': 1664, 'stride_adjustable': False},\n",
        "            'densenet201': {'low_level_layer': 'features.transition1', 'high_level_layer': 'features',\n",
        "                            'low_level_channels': 128, 'high_level_channels': 1920, 'stride_adjustable': False},\n",
        "            'efficientnet_b0': {'low_level_layer': 'features.2', 'high_level_layer': 'features.7',\n",
        "                                'low_level_channels': 24, 'high_level_channels': 320, 'stride_adjustable': False},\n",
        "            'efficientnet_b1': {'low_level_layer': 'features.2', 'high_level_layer': 'features.7',\n",
        "                                'low_level_channels': 24, 'high_level_channels': 320, 'stride_adjustable': False},\n",
        "            'efficientnet_b2': {'low_level_layer': 'features.2', 'high_level_layer': 'features.7',\n",
        "                                'low_level_channels': 24, 'high_level_channels': 352, 'stride_adjustable': False},\n",
        "            'efficientnet_b3': {'low_level_layer': 'features.2', 'high_level_layer': 'features.7',\n",
        "                                'low_level_channels': 32, 'high_level_channels': 384, 'stride_adjustable': False},\n",
        "            'efficientnet_b4': {'low_level_layer': 'features.2', 'high_level_layer': 'features.7',\n",
        "                                'low_level_channels': 32, 'high_level_channels': 448, 'stride_adjustable': False},\n",
        "            'efficientnet_b5': {'low_level_layer': 'features.2', 'high_level_layer': 'features.7',\n",
        "                                'low_level_channels': 40, 'high_level_channels': 512, 'stride_adjustable': False},\n",
        "            'efficientnet_b6': {'low_level_layer': 'features.2', 'high_level_layer': 'features.7',\n",
        "                                'low_level_channels': 40, 'high_level_channels': 576, 'stride_adjustable': False},\n",
        "            'efficientnet_b7': {'low_level_layer': 'features.2', 'high_level_layer': 'features.7',\n",
        "                                'low_level_channels': 48, 'high_level_channels': 640, 'stride_adjustable': False},\n",
        "            'mobilenet_v2': {'low_level_layer': 'features.4', 'high_level_layer': 'features.18',\n",
        "                             'low_level_channels': 32, 'high_level_channels': 1280, 'stride_adjustable': False},\n",
        "        }\n",
        "\n",
        "        if encoder_name not in self.encoder_config:\n",
        "            raise ValueError(f\"Unsupported encoder: {encoder_name}. Supported: {list(self.encoder_config.keys())}\")\n",
        "\n",
        "        config = self.encoder_config[encoder_name]\n",
        "\n",
        "        # Load the encoder with pretrained weights\n",
        "        try:\n",
        "            from torchvision.models import densenet121, DenseNet121_Weights, mobilenet_v2, MobileNet_V2_Weights\n",
        "            if encoder_name == 'densenet121':\n",
        "                self.encoder = densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1)\n",
        "            elif encoder_name == 'mobilenet_v2':\n",
        "                self.encoder = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)\n",
        "                # Adjust stride in features.2 to achieve 64x64 at features.4\n",
        "                if output_stride == 16:\n",
        "                    self.encoder.features[2].conv[1].stride = (1, 1)  # Set stride to 1\n",
        "            else:\n",
        "                self.encoder = getattr(models, encoder_name)(pretrained=True)\n",
        "        except ImportError:\n",
        "            self.encoder = getattr(models, encoder_name)(pretrained=True)\n",
        "\n",
        "        # Adjust strides for ResNet\n",
        "        if config['stride_adjustable'] and output_stride != 32:\n",
        "            if encoder_name.startswith('resnet'):\n",
        "                if output_stride == 16:\n",
        "                    self.encoder.layer4[0].conv2.stride = (1, 1)\n",
        "                    self.encoder.layer4[0].downsample[0].stride = (1, 1)\n",
        "                elif output_stride == 8:\n",
        "                    self.encoder.layer3[0].conv2.stride = (1, 1)\n",
        "                    self.encoder.layer3[0].downsample[0].stride = (1, 1)\n",
        "                    self.encoder.layer4[0].conv2.stride = (1, 1)\n",
        "                    self.encoder.layer4[0].downsample[0].stride = (1, 1)\n",
        "\n",
        "        # Remove classification head\n",
        "        if encoder_name.startswith('resnet'):\n",
        "            self.encoder.fc = nn.Identity()\n",
        "            self.encoder.avgpool = nn.Identity()\n",
        "        elif encoder_name.startswith('densenet'):\n",
        "            self.encoder.classifier = nn.Identity()\n",
        "        elif encoder_name.startswith('efficientnet'):\n",
        "            self.encoder.classifier = nn.Identity()\n",
        "            self.encoder.avgpool = nn.Identity()\n",
        "        elif encoder_name == 'mobilenet_v2':\n",
        "            self.encoder.classifier = nn.Identity()\n",
        "\n",
        "        # Low-level feature projection\n",
        "        self.low_proj = nn.Sequential(\n",
        "            nn.Conv2d(config['low_level_channels'], 48, 1, bias=False),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # ASPP\n",
        "        dilations = [6, 12, 18] if output_stride == 16 else [12, 24, 36]\n",
        "        if bridge == 'ASPP':\n",
        "            self.aspp = ASPP(config['high_level_channels'], 256, dilations)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported bridge: {bridge}. Only 'ASPP' is supported.\")\n",
        "\n",
        "        # MFF, CAFSE, and Decoder\n",
        "        self.mff = MFFBlock(48, 256, 256)\n",
        "        self.decoder = Decoder(256, 256)\n",
        "        self.cafse = CAFSEBlock(256)\n",
        "        self.final_conv = nn.Conv2d(256, num_classes_seg, 1)\n",
        "\n",
        "        # Classifier for mode=0\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(config['high_level_channels'], 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes_cls)\n",
        "        )\n",
        "\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        input_size = x.size()[2:]\n",
        "        print(f\"Input shape: {x.shape}\")\n",
        "\n",
        "        # Feature extraction\n",
        "        if self.encoder_name.startswith('resnet'):\n",
        "            x = self.encoder.conv1(x)\n",
        "            x = self.encoder.bn1(x)\n",
        "            x = self.encoder.relu(x)\n",
        "            x = self.encoder.maxpool(x)\n",
        "            x_low = self.encoder.layer1(x)\n",
        "            x = self.encoder.layer2(x_low)\n",
        "            x = self.encoder.layer3(x)\n",
        "            x_high = self.encoder.layer4(x)\n",
        "        elif self.encoder_name.startswith('densenet'):\n",
        "            x = self.encoder.features.conv0(x)\n",
        "            x = self.encoder.features.norm0(x)\n",
        "            x = self.encoder.features.relu0(x)\n",
        "            x = self.encoder.features.pool0(x)\n",
        "            x = self.encoder.features.denseblock1(x)\n",
        "            x_low = self.encoder.features.transition1(x)\n",
        "            x = self.encoder.features.denseblock2(x_low)\n",
        "            x = self.encoder.features.transition2(x)\n",
        "            x = self.encoder.features.denseblock3(x)\n",
        "            x = self.encoder.features.transition3(x)\n",
        "            x = self.encoder.features.denseblock4(x)\n",
        "            x_high = self.encoder.features.norm5(x)\n",
        "            x_high = F.relu(x_high, inplace=True)\n",
        "        elif self.encoder_name.startswith('efficientnet'):\n",
        "            x = self.encoder.features[0](x)\n",
        "            x = self.encoder.features[1](x)\n",
        "            x_low = self.encoder.features[2](x)\n",
        "            x = self.encoder.features[3](x_low)\n",
        "            x = self.encoder.features[4](x)\n",
        "            x = self.encoder.features[5](x)\n",
        "            x = self.encoder.features[6](x)\n",
        "            x_high = self.encoder.features[7](x)\n",
        "        elif self.encoder_name == 'mobilenet_v2':\n",
        "            x = self.encoder.features[0](x)\n",
        "            x = self.encoder.features[1](x)\n",
        "            x = self.encoder.features[2](x)\n",
        "            x = self.encoder.features[3](x)\n",
        "            x_low = self.encoder.features[4](x)\n",
        "            # print(f\"x_low shape: {x_low.shape}\")\n",
        "            x = self.encoder.features[5](x_low)\n",
        "            x = self.encoder.features[6](x)\n",
        "            x = self.encoder.features[7](x)\n",
        "            x = self.encoder.features[8](x)\n",
        "            x = self.encoder.features[9](x)\n",
        "            x = self.encoder.features[10](x)\n",
        "            x = self.encoder.features[11](x)\n",
        "            x = self.encoder.features[12](x)\n",
        "            x = self.encoder.features[13](x)\n",
        "            x = self.encoder.features[14](x)\n",
        "            x = self.encoder.features[15](x)\n",
        "            x = self.encoder.features[16](x)\n",
        "            x = self.encoder.features[17](x)\n",
        "            x_high = self.encoder.features[18](x)\n",
        "            # print(f\"x_high shape: {x_high.shape}\")\n",
        "\n",
        "        # Classification mode\n",
        "        if self.mode == 0:\n",
        "            out = self.classifier(x_high)\n",
        "            return out\n",
        "\n",
        "        # Segmentation mode\n",
        "        low_proj = self.low_proj(x_low)\n",
        "        # print(f\"low_proj output shape: {low_proj.shape}\")\n",
        "        aspp_out = self.aspp(x_high)\n",
        "        # print(f\"aspp_out shape: {aspp_out.shape}\")\n",
        "        mff_out = self.mff(low_proj, aspp_out)\n",
        "        # print(f\"mff_out shape: {mff_out.shape}\")\n",
        "        decoder_out = self.decoder(mff_out, low_proj)\n",
        "        # print(f\"decoder_out shape: {decoder_out.shape}\")\n",
        "        cafse_out = self.cafse(decoder_out, aspp_out)\n",
        "        # print(f\"cafse_out shape: {cafse_out.shape}\")\n",
        "        out = self.final_conv(cafse_out)\n",
        "        # print(f\"final_conv output shape: {out.shape}\")\n",
        "        out = F.interpolate(out, size=input_size, mode='bilinear', align_corners=True)\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "# Function to print model parameters\n",
        "def print_model_parameters(model):\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    non_trainable_params = total_params - trainable_params\n",
        "    print(f\"Total Parameters: {total_params:,}\")\n",
        "    print(f\"Trainable Parameters: {trainable_params:,}\")\n",
        "    print(f\"Non-Trainable Parameters: {non_trainable_params:,}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = DeepLabV3Plus(encoder_name=ENCODER_NAME, bridge='ASPP', num_classes_seg=NUM_CLASS_SEG, num_classes_cls=NUM_CLASS_CLS, mode=MODE, output_stride=16)\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    # Input image\n",
        "    input_tensor = torch.randn(2, 3, 256, 256).to(DEVICE)\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(input_tensor)\n",
        "    print(f\"Output shape: {output.shape}\")\n",
        "\n",
        "    # Print model parameters\n",
        "    print_model_parameters(model)\n",
        "\n",
        "    # Model summary using torchinfo\n",
        "    try:\n",
        "        from torchinfo import summary\n",
        "        summary(model, input_size=(2, 3, 256, 256), device=DEVICE)\n",
        "    except ImportError:\n",
        "        print(\"torchinfo not installed. Install it using 'pip install torchinfo' for model summary.\")\n",
        "\n",
        "\n",
        "!pip install thop\n",
        "\n",
        "\n",
        "import torch\n",
        "import time\n",
        "from scipy.stats import ttest_ind\n",
        "import psutil\n",
        "from thop import profile\n",
        "\n",
        "# Dummy input (batch of 32, 3 channels, 256x256)\n",
        "num_frames = 100\n",
        "dummy_input = torch.randn(1, 3, 256, 256).cuda()\n",
        "\n",
        "# Set device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Parameters\n",
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6  # Convert to millions\n",
        "print(f\"Params: {params:.2f} M\")\n",
        "\n",
        "# GFlops (using thop)\n",
        "flops, params_thop = profile(model, inputs=(dummy_input,))  # Returns flops and params\n",
        "gflops = flops / 1e9  # Convert to gigaflops\n",
        "print(f\"GFlops: {gflops:.2f} G\")\n",
        "\n",
        "# Memory\n",
        "# Reset memory stats to ensure accurate measurement\n",
        "torch.cuda.reset_peak_memory_stats(DEVICE)\n",
        "\n",
        "# Measure model parameters memory\n",
        "param_memory = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024 * 1024)  # MB\n",
        "buffer_memory = sum(b.numel() * b.element_size() for b in model.buffers()) / (1024 * 1024)  # MB\n",
        "model_memory = param_memory + buffer_memory\n",
        "print(f\"Model Parameters + Buffers Memory: {model_memory:.2f} MB\")\n",
        "\n",
        "# Measure memory during inference (including activations)\n",
        "torch.cuda.synchronize()  # Ensure no pending operations\n",
        "start_memory = torch.cuda.memory_allocated(DEVICE) / (1024 * 1024)  # MB\n",
        "model(dummy_input)  # Run a forward pass\n",
        "torch.cuda.synchronize()  # Wait for GPU operations to complete\n",
        "peak_memory = torch.cuda.max_memory_allocated(DEVICE) / (1024 * 1024)  # MB\n",
        "print(f\"Peak Memory During Inference: {peak_memory:.2f} MB\")\n",
        "print(f\"Memory Allocated for Input + Activations: {peak_memory - model_memory:.2f} MB\")\n",
        "\n",
        "# Optional: Reserved memory (includes cached memory by PyTorch)\n",
        "reserved_memory = torch.cuda.memory_reserved(DEVICE) / (1024 * 1024)  # MB\n",
        "print(f\"Reserved Memory: {reserved_memory:.2f} MB\")\n",
        "\n",
        "# FPS\n",
        "start = time.time()\n",
        "for _ in range(num_frames):\n",
        "    model(dummy_input)\n",
        "torch.cuda.synchronize()  # Ensure GPU operations complete\n",
        "fps = num_frames / (time.time() - start)\n",
        "print(f\"FPS: {fps:.2f}\")\n",
        "\n",
        "print(\"--------[RESOURCE INFO]---------\")\n",
        "print(f\"Params: {params:.2f} M\")\n",
        "print(f\"GFlops: {gflops:.2f} G\")\n",
        "# print(f\"Memory: {memory:.2f} MB\")\n",
        "print(f\"FPS: {fps:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yiwOTpS_vNl",
        "outputId": "a07a1997-b159-4eef-df72-b5b5fd92bc72"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([2, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([2, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "Output shape: torch.Size([2, 2, 256, 256])\n",
            "Total Parameters: 10,603,972\n",
            "Trainable Parameters: 10,603,972\n",
            "Non-Trainable Parameters: 0\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([2, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([2, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.12/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->thop) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->thop) (3.0.2)\n",
            "Using device: cuda\n",
            "Params: 10.60 M\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "GFlops: 5.35 G\n",
            "Model Parameters + Buffers Memory: 40.79 MB\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Peak Memory During Inference: 700.06 MB\n",
            "Memory Allocated for Input + Activations: 659.27 MB\n",
            "Reserved Memory: 1026.00 MB\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Input shape: torch.Size([1, 3, 256, 256])\n",
            "ASPP input shape: torch.Size([1, 1024, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([1, 1280, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([1, 48, 32, 32])\n",
            "MFFBlock high_feat shape: torch.Size([1, 256, 8, 8])\n",
            "Decoder input x shape: torch.Size([1, 256, 32, 32])\n",
            "Decoder low_level_feat shape: torch.Size([1, 48, 32, 32])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([1, 256, 32, 32])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([1, 256, 8, 8])\n",
            "FPS: 37.46\n",
            "--------[RESOURCE INFO]---------\n",
            "Params: 10.60 M\n",
            "GFlops: 5.35 G\n",
            "FPS: 37.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics Define & Others"
      ],
      "metadata": {
        "id": "u4qwUrVIZERw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Metrics definitions (ensure these are defined earlier in your code)\n",
        "class DiceCoefficient(torch.nn.Module):\n",
        "    def __init__(self, threshold=0.5):\n",
        "        super(DiceCoefficient, self).__init__()\n",
        "        self.threshold = threshold\n",
        "        self.__name__ = \"DiceCoefficient\"  # Add the __name__ attribute\n",
        "\n",
        "    def forward(self, y_true, y_pred):\n",
        "        y_pred = torch.sigmoid(y_pred)  # Apply sigmoid if predictions are logits\n",
        "        y_pred = (y_pred > self.threshold).float()  # Apply threshold\n",
        "\n",
        "        intersection = (y_true * y_pred).sum(dim=(2, 3))  # Sum over height and width\n",
        "        union = (y_true + y_pred).sum(dim=(2, 3))\n",
        "\n",
        "        dice = 2. * intersection / (union + 1e-6)  # Add epsilon to avoid division by zero\n",
        "        return dice.mean()  # Mean over the batch\n",
        "\n",
        "\n",
        "\n",
        "class IoU(torch.nn.Module):\n",
        "    def __init__(self, threshold=0.5, eps=1e-7, activation=None):\n",
        "        \"\"\"\n",
        "        Intersection over Union (IoU) metric similar to SMP's implementation.\n",
        "\n",
        "        Args:\n",
        "            threshold (float): Threshold for converting probabilities to binary predictions.\n",
        "            eps (float): Small value to avoid division by zero.\n",
        "            activation (callable, optional): Activation function to apply to predictions (e.g., torch.sigmoid).\n",
        "                                             If None, assumes inputs are already probabilities.\n",
        "        \"\"\"\n",
        "        super(IoU, self).__init__()\n",
        "        self.threshold = threshold\n",
        "        self.eps = eps\n",
        "        self.activation = activation\n",
        "        self.__name__ = \"IoU\"  # For compatibility with metric logging\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "\n",
        "        # Apply activation if provided (e.g., sigmoid for logits)\n",
        "        if self.activation is not None:\n",
        "            y_pred = self.activation(y_pred)\n",
        "\n",
        "        # Convert probabilities to binary predictions using threshold\n",
        "        y_pred = (y_pred > self.threshold).float()\n",
        "\n",
        "        # Ensure inputs are binary and have matching shapes\n",
        "        y_true = y_true.float()\n",
        "        assert y_pred.shape == y_true.shape, f\"Shape mismatch: y_pred {y_pred.shape}, y_true {y_true.shape}\"\n",
        "\n",
        "        # Compute intersection and union\n",
        "        intersection = (y_pred * y_true).sum(dim=(2, 3))  # Sum over H and W dimensions\n",
        "        union = (y_pred + y_true - y_pred * y_true).sum(dim=(2, 3))  # Union = A + B - A∩B\n",
        "\n",
        "        # Compute IoU with epsilon to avoid division by zero\n",
        "        iou = (intersection + self.eps) / (union + self.eps)\n",
        "\n",
        "        # Return mean IoU over the batch\n",
        "        return iou.mean()\n",
        "\n",
        "class AUC(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AUC, self).__init__()\n",
        "        self.__name__ = \"AUC\"\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        # For a proper AUC, you would accumulate predictions and labels for the whole dataset\n",
        "        # Here we use a rough approximation per batch by binarizing with a threshold\n",
        "        y_pred = torch.sigmoid(y_pred).view(-1)\n",
        "        y_true = y_true.view(-1).float()\n",
        "        y_pred = y_pred.detach().cpu().numpy()\n",
        "        y_true = y_true.detach().cpu().numpy()\n",
        "\n",
        "        from sklearn.metrics import roc_auc_score\n",
        "        try:\n",
        "            auc = roc_auc_score(y_true, y_pred)\n",
        "        except ValueError:\n",
        "            auc = 0.5  # Fallback if only one class is present\n",
        "        return torch.tensor(auc)\n",
        "\n",
        "class Accuracy(torch.nn.Module):\n",
        "    def __init__(self, threshold=0.5):\n",
        "        super(Accuracy, self).__init__()\n",
        "        self.threshold = threshold\n",
        "        self.__name__ = \"Accuracy\"  # ✅ Add this\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        # y_pred is already sigmoid activated\n",
        "        y_pred = (y_pred > self.threshold).float()\n",
        "        y_true = y_true.float()\n",
        "        correct = (y_pred == y_true).float()\n",
        "        return correct.mean()\n",
        "\n",
        "\n",
        "class Precision(torch.nn.Module):\n",
        "    def __init__(self, threshold=0.5, eps=1e-7):\n",
        "        super(Precision, self).__init__()\n",
        "        self.threshold = threshold\n",
        "        self.eps = eps\n",
        "        self.__name__ = \"Precision\"\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        y_pred = (y_pred > self.threshold).float()\n",
        "        y_true = y_true.float()\n",
        "\n",
        "        TP = (y_pred * y_true).sum(dim=(2, 3))\n",
        "        FP = (y_pred * (1 - y_true)).sum(dim=(2, 3))\n",
        "\n",
        "        precision = (TP + self.eps) / (TP + FP + self.eps)\n",
        "        return precision.mean()\n",
        "\n",
        "\n",
        "class Recall(torch.nn.Module):\n",
        "    def __init__(self, threshold=0.5, eps=1e-7):\n",
        "        super(Recall, self).__init__()\n",
        "        self.threshold = threshold\n",
        "        self.eps = eps\n",
        "        self.__name__ = \"Recall\"\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        y_pred = (y_pred > self.threshold).float()\n",
        "        y_true = y_true.float()\n",
        "\n",
        "        TP = (y_pred * y_true).sum(dim=(2, 3))\n",
        "        FN = ((1 - y_pred) * y_true).sum(dim=(2, 3))\n",
        "\n",
        "        recall = (TP + self.eps) / (TP + FN + self.eps)\n",
        "        return recall.mean()\n",
        "\n",
        "\n",
        "class F1Score(torch.nn.Module):\n",
        "    def __init__(self, threshold=0.5, eps=1e-7):\n",
        "        super(F1Score, self).__init__()\n",
        "        self.threshold = threshold\n",
        "        self.eps = eps\n",
        "        self.__name__ = \"F1Score\"\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        y_pred = (y_pred > self.threshold).float()\n",
        "        y_true = y_true.float()\n",
        "\n",
        "        TP = (y_pred * y_true).sum(dim=(2, 3))\n",
        "        FP = (y_pred * (1 - y_true)).sum(dim=(2, 3))\n",
        "        FN = ((1 - y_pred) * y_true).sum(dim=(2, 3))\n",
        "\n",
        "        precision = (TP + self.eps) / (TP + FP + self.eps)\n",
        "        recall = (TP + self.eps) / (TP + FN + self.eps)\n",
        "        f1 = 2 * precision * recall / (precision + recall + self.eps)\n",
        "        return f1.mean()\n",
        "\n",
        "dice_metric = DiceCoefficient(threshold=0.5)\n",
        "iou_metric = IoU(threshold=0.5)\n",
        "auc_metric = AUC()"
      ],
      "metadata": {
        "id": "njvDMwJw3Xhf",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:46:40.149946Z",
          "iopub.execute_input": "2025-09-06T07:46:40.150186Z",
          "iopub.status.idle": "2025-09-06T07:46:40.167537Z",
          "shell.execute_reply.started": "2025-09-06T07:46:40.150159Z",
          "shell.execute_reply": "2025-09-06T07:46:40.166794Z"
        }
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "class ThresholdedDiceLoss(torch.nn.Module):\n",
        "    def __init__(self, threshold=0.5):\n",
        "        super(ThresholdedDiceLoss, self).__init__()\n",
        "        self.threshold = threshold\n",
        "        self.__name__ = 'dice_loss'  # Add the __name__ attribute\n",
        "\n",
        "    def forward(self, y_true, y_pred):\n",
        "        # Apply sigmoid if the predictions are logits (before thresholding)\n",
        "        y_pred = torch.sigmoid(y_pred)\n",
        "\n",
        "        # Apply thresholding to the predicted probabilities\n",
        "        y_pred = (y_pred > self.threshold).float()\n",
        "\n",
        "        # Calculate intersection and union\n",
        "        intersection = (y_true * y_pred).sum(dim=(2, 3))  # Sum over height and width\n",
        "        union = (y_true + y_pred).sum(dim=(2, 3))\n",
        "\n",
        "        # Calculate Dice coefficient and return the loss (1 - Dice coefficient)\n",
        "        dice = 2. * intersection / (union + 1e-6)  # Add epsilon to avoid division by zero\n",
        "        return 1 - dice.mean()  # Loss is 1 - Dice coefficient, averaged over the batch\n",
        "\n",
        "\n",
        "loss_fn = ThresholdedDiceLoss(threshold=0.5)\n",
        "\n",
        "# Early Stopping class\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=1e-20, metric='val_iou'):\n",
        "        self.patience = patience  # Number of epochs to wait for improvement\n",
        "        self.min_delta = min_delta  # Minimum improvement required\n",
        "        self.metric = metric  # Metric to monitor ('val_iou', 'val_dice', or 'val_loss')\n",
        "        self.best_score = None\n",
        "        self.wait = 0\n",
        "        self.stop_training = False\n",
        "\n",
        "    def __call__(self, metrics_dict):\n",
        "        current_score = metrics_dict[self.metric]\n",
        "        if self.metric == 'val_loss':\n",
        "            current_score = -current_score  # Lower loss is better, so negate for consistency\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = current_score\n",
        "        elif current_score < self.best_score + self.min_delta:\n",
        "            self.wait += 1\n",
        "            print(f\"No improvement in {self.metric}. Wait: {self.wait}/{self.patience}\")\n",
        "            if self.wait >= self.patience:\n",
        "                self.stop_training = True\n",
        "                print(f\"Early stopping triggered after {self.wait} epochs without improvement!\")\n",
        "        else:\n",
        "            self.best_score = current_score\n",
        "            self.wait = 0\n",
        "\n",
        "# One-hot encoding and decoding\n",
        "def one_hot_encode(label, label_values):\n",
        "    semantic_map = []\n",
        "    for colour in label_values:\n",
        "        equality = np.equal(label, colour)\n",
        "        class_map = np.all(equality, axis=-1)\n",
        "        semantic_map.append(class_map)\n",
        "    return np.stack(semantic_map, axis=-1)\n",
        "\n",
        "def reverse_one_hot(image):\n",
        "    return np.argmax(image, axis=-1)\n",
        "\n",
        "def colour_code_segmentation(image, label_values):\n",
        "    colour_codes = np.array(label_values)\n",
        "    return colour_codes[image.astype(int)]"
      ],
      "metadata": {
        "id": "5vCw0Hdk3421",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:46:40.168316Z",
          "iopub.execute_input": "2025-09-06T07:46:40.168535Z",
          "iopub.status.idle": "2025-09-06T07:46:40.187041Z",
          "shell.execute_reply.started": "2025-09-06T07:46:40.168518Z",
          "shell.execute_reply": "2025-09-06T07:46:40.186328Z"
        }
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "# List files in the imported dataset directory to verify\n",
        "!ls {shadmansobhan_dataset_mp_review_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWIOfwgFbjXT",
        "outputId": "58a62f38-b61d-4601-b13d-2812d3c39a63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined_GI_Tract  Combined_RBV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the threshold\n",
        "threshold = np.array([112, 127, 127])\n",
        "\n",
        "# Define the input directory for masks\n",
        "mask_dir = f'{shadmansobhan_dataset_mp_review_path}/{DATASET_NAME}/Train/Mask'\n",
        "\n",
        "# List all files in the mask directory\n",
        "mask_files = os.listdir(mask_dir)\n",
        "\n",
        "# Iterate through each mask file\n",
        "for mask_filename in mask_files:\n",
        "    mask_path = os.path.join(mask_dir, mask_filename)\n",
        "\n",
        "    # Read the image\n",
        "    mask_img = cv2.imread(mask_path)\n",
        "\n",
        "    if mask_img is None:\n",
        "        print(f\"Could not read image: {mask_path}\")\n",
        "        continue\n",
        "\n",
        "    # Check if the image is grayscale or color and convert to BGR if needed for comparison\n",
        "    if len(mask_img.shape) == 2: # Grayscale\n",
        "        # Convert grayscale to 3 channels to compare with a 3-channel threshold\n",
        "        mask_img_color = cv2.cvtColor(mask_img, cv2.COLOR_GRAY2BGR)\n",
        "    else: # Color image\n",
        "        mask_img_color = mask_img.copy() # Work on a copy\n",
        "\n",
        "    # Create a boolean mask where pixels are less than the threshold in all channels\n",
        "    # Note: cv2.threshold and similar functions are typically for single-channel images.\n",
        "    # We can use numpy broadcasting and boolean indexing for multi-channel thresholding.\n",
        "    mask_below_threshold = np.all(mask_img_color < threshold, axis=-1)\n",
        "\n",
        "    # Create the output image (initialized to black)\n",
        "    thresholded_mask = np.zeros_like(mask_img_color, dtype=np.uint8)\n",
        "\n",
        "    # Set pixels greater than or equal to the threshold to [255, 255, 255] (white)\n",
        "    # The condition is the opposite of mask_below_threshold\n",
        "    thresholded_mask[~mask_below_threshold] = [255, 255, 255]\n",
        "\n",
        "    # Save the thresholded image back to the same location (overwriting the original mask)\n",
        "    cv2.imwrite(mask_path, thresholded_mask)\n",
        "\n",
        "print(\"Mask images on Train/Masks have been thresholded.\")"
      ],
      "metadata": {
        "id": "8y68mSHZANbf",
        "outputId": "93bf3d8c-75ac-46c3-f294-2b106e67ac45",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:46:40.187602Z",
          "iopub.execute_input": "2025-09-06T07:46:40.187818Z",
          "iopub.status.idle": "2025-09-06T07:46:40.631602Z",
          "shell.execute_reply.started": "2025-09-06T07:46:40.187801Z",
          "shell.execute_reply": "2025-09-06T07:46:40.630941Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mask images on Train/Masks have been thresholded.\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input directory for masks\n",
        "mask_dir = f'{shadmansobhan_dataset_mp_review_path}/{DATASET_NAME}/Test/Mask'\n",
        "\n",
        "# List all files in the mask directory\n",
        "mask_files = os.listdir(mask_dir)\n",
        "\n",
        "# Iterate through each mask file\n",
        "for mask_filename in mask_files:\n",
        "    mask_path = os.path.join(mask_dir, mask_filename)\n",
        "\n",
        "    # Read the image\n",
        "    mask_img = cv2.imread(mask_path)\n",
        "\n",
        "    if mask_img is None:\n",
        "        print(f\"Could not read image: {mask_path}\")\n",
        "        continue\n",
        "\n",
        "    # Check if the image is grayscale or color and convert to BGR if needed for comparison\n",
        "    if len(mask_img.shape) == 2: # Grayscale\n",
        "        # Convert grayscale to 3 channels to compare with a 3-channel threshold\n",
        "        mask_img_color = cv2.cvtColor(mask_img, cv2.COLOR_GRAY2BGR)\n",
        "    else: # Color image\n",
        "        mask_img_color = mask_img.copy() # Work on a copy\n",
        "\n",
        "    # Create a boolean mask where pixels are less than the threshold in all channels\n",
        "    mask_below_threshold = np.all(mask_img_color < threshold, axis=-1)\n",
        "\n",
        "    # Create the output image (initialized to black)\n",
        "    thresholded_mask = np.zeros_like(mask_img_color, dtype=np.uint8)\n",
        "\n",
        "    # Set pixels greater than or equal to the threshold to [255, 255, 255] (white)\n",
        "    # The condition is the opposite of mask_below_threshold\n",
        "    thresholded_mask[~mask_below_threshold] = [255, 255, 255]\n",
        "\n",
        "    # Save the thresholded image back to the same location (overwriting the original mask)\n",
        "    cv2.imwrite(mask_path, thresholded_mask)\n",
        "\n",
        "print(\"Mask images on Test/Masks have been thresholded.\")\n"
      ],
      "metadata": {
        "id": "T25hxW6fBziM",
        "outputId": "7e6cde93-2038-4268-a6c6-cdcd4568f022",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:46:40.632452Z",
          "iopub.execute_input": "2025-09-06T07:46:40.632712Z",
          "iopub.status.idle": "2025-09-06T07:46:40.859864Z",
          "shell.execute_reply.started": "2025-09-06T07:46:40.632693Z",
          "shell.execute_reply": "2025-09-06T07:46:40.859193Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mask images on Test/Masks have been thresholded.\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base directory for the dataset\n",
        "dataset_base_dir = f'{shadmansobhan_dataset_mp_review_path}/{DATASET_NAME}'\n",
        "train_dir = os.path.join(dataset_base_dir, 'Train')\n",
        "test_dir = os.path.join(dataset_base_dir, 'Test')\n",
        "\n",
        "# List image files in the Train directory\n",
        "train_image_files = [f for f in os.listdir(os.path.join(train_dir, 'Image')) if f.endswith('.png')]\n",
        "\n",
        "# Create a list of full paths for the training images and masks\n",
        "train_image_paths = [os.path.join(train_dir, 'Image', f) for f in train_image_files]\n",
        "train_mask_paths = [os.path.join(train_dir, 'Mask', f) for f in train_image_files] # Assuming mask filenames match image filenames\n",
        "\n",
        "# Create a DataFrame for the training data\n",
        "train_df_full = pd.DataFrame({'image_path': train_image_paths, 'mask_path': train_mask_paths})\n",
        "\n",
        "# Split the full training data into training and validation sets\n",
        "train_df, valid_df = train_test_split(train_df_full, test_size=0.1, random_state=42) # 90% train, 10% validation\n",
        "\n",
        "# Reset indices after splitting\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "valid_df = valid_df.reset_index(drop=True)\n",
        "\n",
        "# List image files in the Test directory\n",
        "test_image_files = [f for f in os.listdir(os.path.join(test_dir, 'Image')) if f.endswith('.png')]\n",
        "\n",
        "# Create a list of full paths for the test images and masks\n",
        "test_image_paths = [os.path.join(test_dir, 'Image', f) for f in test_image_files]\n",
        "test_mask_paths = [os.path.join(test_dir, 'Mask', f) for f in test_image_files] # Assuming mask filenames match image filenames\n",
        "\n",
        "# Create a DataFrame for the test data\n",
        "test_df = pd.DataFrame({'image_path': test_image_paths, 'mask_path': test_mask_paths})\n",
        "\n",
        "print(f\"Number of training samples: {len(train_df)}\")\n",
        "print(f\"Number of validation samples: {len(valid_df)}\")\n",
        "print(f\"Number of test samples: {len(test_df)}\")\n",
        "\n",
        "# Display the first few rows of each DataFrame\n",
        "print(\"\\nTrain DataFrame:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nValidation DataFrame:\")\n",
        "print(valid_df.head())\n",
        "print(\"\\nTest DataFrame:\")\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "id": "2sQcJM286saZ",
        "outputId": "b9d290f2-6c8e-4f8a-9998-2e4d4a1dfe9f",
        "scrolled": true,
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:46:40.862055Z",
          "iopub.execute_input": "2025-09-06T07:46:40.862519Z",
          "iopub.status.idle": "2025-09-06T07:46:40.892182Z",
          "shell.execute_reply.started": "2025-09-06T07:46:40.862498Z",
          "shell.execute_reply": "2025-09-06T07:46:40.891431Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 52\n",
            "Number of validation samples: 6\n",
            "Number of test samples: 30\n",
            "\n",
            "Train DataFrame:\n",
            "                                          image_path  \\\n",
            "0  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "1  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "2  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "3  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "4  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "\n",
            "                                           mask_path  \n",
            "0  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "1  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "2  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "3  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "4  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "\n",
            "Validation DataFrame:\n",
            "                                          image_path  \\\n",
            "0  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "1  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "2  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "3  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "4  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "\n",
            "                                           mask_path  \n",
            "0  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "1  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "2  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "3  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "4  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "\n",
            "Test DataFrame:\n",
            "                                          image_path  \\\n",
            "0  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "1  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "2  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "3  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "4  /kaggle/input/dataset-mp-review/Combined_RBV/T...   \n",
            "\n",
            "                                           mask_path  \n",
            "0  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "1  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "2  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "3  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n",
            "4  /kaggle/input/dataset-mp-review/Combined_RBV/T...  \n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataGenerator(Dataset):\n",
        "    def __init__(self, df, class_rgb_values, augmentation=None, preprocessing=None):\n",
        "        self.image_paths = df['image_path'].tolist()\n",
        "        self.mask_paths = df['mask_path'].tolist()\n",
        "        self.class_rgb_values = class_rgb_values\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        image = cv2.cvtColor(cv2.imread(self.image_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.cvtColor(cv2.imread(self.mask_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # One-hot encode to shape (H, W, C), values in {0, 1}\n",
        "        mask = one_hot_encode(mask, self.class_rgb_values).astype('float')  # ✅ no division\n",
        "\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "\n",
        "# Augmentations\n",
        "def get_training_augmentation():\n",
        "    return album.Compose([\n",
        "        album.HorizontalFlip(p=0.5),  # Existing: Randomly flip horizontally\n",
        "        album.VerticalFlip(p=0.5),    # Randomly flip vertically (polyps can appear in any orientation)\n",
        "    ])\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    return album.Compose([\n",
        "        album.PadIfNeeded(min_height=256, min_width=256, always_apply=True, border_mode=cv2.BORDER_CONSTANT, value=0)\n",
        "    ])\n",
        "\n",
        "def to_tensor(x, **kwargs):\n",
        "    return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "def get_preprocessing():\n",
        "    return album.Compose([\n",
        "        album.Resize(height=256, width=256, always_apply=True),  # Resize to 256x256\n",
        "        album.Lambda(image=to_tensor, mask=to_tensor)  # Convert to tensor\n",
        "    ])\n",
        "\n",
        "select_class_rgb_values = np.array([[0, 0, 0],\n",
        "                            [255, 255, 255]])"
      ],
      "metadata": {
        "id": "gg96EaYl7ktj",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:46:40.89302Z",
          "iopub.execute_input": "2025-09-06T07:46:40.893284Z",
          "iopub.status.idle": "2025-09-06T07:46:40.901729Z",
          "shell.execute_reply.started": "2025-09-06T07:46:40.893259Z",
          "shell.execute_reply": "2025-09-06T07:46:40.901053Z"
        }
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize data loaders\n",
        "train_dataset = MyDataGenerator(train_df, select_class_rgb_values, get_training_augmentation(), get_preprocessing())\n",
        "valid_dataset = MyDataGenerator(valid_df, select_class_rgb_values, get_validation_augmentation(), get_preprocessing())\n",
        "test_dataset = MyDataGenerator(test_df, select_class_rgb_values, get_validation_augmentation(), get_preprocessing())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=4)\n",
        "\n",
        "# Initialize model, loss, optimizer, and scheduler\n",
        "model = DeepLabV3Plus(encoder_name=ENCODER_NAME, num_classes_cls=NUM_CLASS_CLS, num_classes_seg=NUM_CLASS_SEG, mode=MODE).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2, eta_min=1e-9)\n",
        "\n",
        "# Metric storage lists\n",
        "train_loss_list, valid_loss_list = [], []\n",
        "train_dice_list, valid_dice_list = [], []\n",
        "train_iou_list, valid_iou_list = [], []\n",
        "\n",
        "# Training loop\n",
        "EPOCHS = 500\n",
        "best_iou = 0.0\n",
        "early_stopping = EarlyStopping(patience=50, min_delta=1e-20, metric='val_iou')\n",
        "# Start timing\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss, train_dice, train_iou = 0.0, 0.0, 0.0\n",
        "\n",
        "    for images, masks in train_loader:\n",
        "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(images)\n",
        "        loss = loss_fn(preds, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        train_dice += dice_metric(preds, masks).item() * images.size(0)\n",
        "        train_iou += iou_metric(preds, masks).item() * images.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_dice /= len(train_loader.dataset)\n",
        "    train_iou /= len(train_loader.dataset)\n",
        "\n",
        "    model.eval()\n",
        "    valid_loss, valid_dice, valid_iou = 0.0, 0.0, 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in valid_loader:\n",
        "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "            preds = model(images)\n",
        "            loss = loss_fn(preds, masks)\n",
        "\n",
        "            valid_loss += loss.item() * images.size(0)\n",
        "            valid_dice += dice_metric(preds, masks).item() * images.size(0)\n",
        "            valid_iou += iou_metric(preds, masks).item() * images.size(0)\n",
        "\n",
        "    valid_loss /= len(valid_loader.dataset)\n",
        "    valid_dice /= len(valid_loader.dataset)\n",
        "    valid_iou /= len(valid_loader.dataset)\n",
        "\n",
        "    # Logging\n",
        "    print(f\"Epoch {epoch+1}: \"\n",
        "          f\"Train Loss={train_loss:.4f}, Train Dice={train_dice:.4f}, Train IoU={train_iou:.4f}, \"\n",
        "          f\"Valid Loss={valid_loss:.4f}, Valid Dice={valid_dice:.4f}, Valid IoU={valid_iou:.4f}\")\n",
        "\n",
        "    # Store metrics\n",
        "    train_loss_list.append(train_loss)\n",
        "    valid_loss_list.append(valid_loss)\n",
        "\n",
        "    train_dice_list.append(train_dice)\n",
        "    valid_dice_list.append(valid_dice)\n",
        "\n",
        "    train_iou_list.append(train_iou)\n",
        "    valid_iou_list.append(valid_iou)\n",
        "\n",
        "    # Save best model\n",
        "    if valid_iou > best_iou:\n",
        "        best_iou = valid_iou\n",
        "        torch.save(model.state_dict(), 'Seg_RetinaVessel_ColorFundus.pth')\n",
        "        print(\"Model saved!\")\n",
        "\n",
        "    # Early stopping\n",
        "    metrics_dict = {'val_loss': valid_loss, 'val_dice': valid_dice, 'val_iou': valid_iou}\n",
        "    early_stopping(metrics_dict)\n",
        "    if early_stopping.stop_training:\n",
        "        print(f\"Training stopped at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "# End timing\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"\\nTotal training time: {elapsed_time / 60:.2f} minutes\")"
      ],
      "metadata": {
        "id": "fZ3lMlxJ4Xqu",
        "outputId": "7794baa4-c4f2-4176-d9f9-04733b0e9a6e",
        "trusted": true,
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:46:40.902563Z",
          "iopub.execute_input": "2025-09-06T07:46:40.902885Z",
          "iopub.status.idle": "2025-09-06T07:54:18.835259Z",
          "shell.execute_reply.started": "2025-09-06T07:46:40.902867Z",
          "shell.execute_reply": "2025-09-06T07:54:18.834318Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 104MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Epoch 1: Train Loss=0.4577, Train Dice=0.5423, Train IoU=0.5058, Valid Loss=0.3844, Valid Dice=0.6156, Valid IoU=0.5807\n",
            "Model saved!\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Epoch 2: Train Loss=0.3323, Train Dice=0.6677, Train IoU=0.5913, Valid Loss=0.3023, Valid Dice=0.6977, Valid IoU=0.6053\n",
            "Model saved!\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Epoch 3: Train Loss=0.3024, Train Dice=0.6976, Train IoU=0.6084, Valid Loss=0.2849, Valid Dice=0.7151, Valid IoU=0.6175\n",
            "Model saved!\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Epoch 4: Train Loss=0.2952, Train Dice=0.7048, Train IoU=0.6124, Valid Loss=0.2763, Valid Dice=0.7237, Valid IoU=0.6249\n",
            "Model saved!\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Epoch 5: Train Loss=0.2837, Train Dice=0.7163, Train IoU=0.6208, Valid Loss=0.2699, Valid Dice=0.7301, Valid IoU=0.6296\n",
            "Model saved!\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Epoch 6: Train Loss=0.2776, Train Dice=0.7224, Train IoU=0.6271, Valid Loss=0.2667, Valid Dice=0.7333, Valid IoU=0.6352\n",
            "Model saved!\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Epoch 7: Train Loss=0.2728, Train Dice=0.7272, Train IoU=0.6328, Valid Loss=0.2613, Valid Dice=0.7387, Valid IoU=0.6400\n",
            "Model saved!\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Epoch 8: Train Loss=0.2757, Train Dice=0.7243, Train IoU=0.6315, Valid Loss=0.2588, Valid Dice=0.7412, Valid IoU=0.6441\n",
            "Model saved!\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Epoch 9: Train Loss=0.2716, Train Dice=0.7284, Train IoU=0.6347, Valid Loss=0.2564, Valid Dice=0.7436, Valid IoU=0.6452\n",
            "Model saved!\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Epoch 10: Train Loss=0.2678, Train Dice=0.7322, Train IoU=0.6396, Valid Loss=0.2555, Valid Dice=0.7445, Valid IoU=0.6446\n",
            "No improvement in val_iou. Wait: 1/50\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Epoch 11: Train Loss=0.2605, Train Dice=0.7395, Train IoU=0.6462, Valid Loss=0.2504, Valid Dice=0.7496, Valid IoU=0.6501\n",
            "Model saved!\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n",
            "Input shape: torch.Size([2, 3, 256, 256])\n",
            "low_proj output shape: torch.Size([2, 48, 64, 64])\n",
            "ASPP input shape: torch.Size([2, 320, 8, 8])\n",
            "ASPP concatenated shape: torch.Size([2, 1280, 8, 8])\n",
            "aspp_out shape: torch.Size([2, 256, 8, 8])\n",
            "MFFBlock low_feat shape: torch.Size([2, 48, 64, 64])\n",
            "MFFBlock high_feat shape: torch.Size([2, 256, 8, 8])\n",
            "mff_out shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder input x shape: torch.Size([2, 256, 64, 64])\n",
            "Decoder low_level_feat shape: torch.Size([2, 48, 64, 64])\n",
            "decoder_out shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock decoder_feat shape: torch.Size([2, 256, 64, 64])\n",
            "CAFSEBlock aspp_feat shape: torch.Size([2, 256, 8, 8])\n",
            "cafse_out shape: torch.Size([2, 256, 64, 64])\n",
            "final_conv output shape: torch.Size([2, 2, 64, 64])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4068983867.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "epochs_range = range(1, len(train_loss_list) + 1)\n",
        "plt.figure(figsize=(18, 5))\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(epochs_range, train_loss_list, label='Train Loss')\n",
        "plt.plot(epochs_range, valid_loss_list, label='Val Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Dice score plot\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(epochs_range, train_dice_list, label='Train Dice')\n",
        "plt.plot(epochs_range, valid_dice_list, label='Val Dice')\n",
        "plt.title('Dice Score over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Dice Score')\n",
        "plt.legend()\n",
        "\n",
        "# IoU plot\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(epochs_range, train_iou_list, label='Train IoU')\n",
        "plt.plot(epochs_range, valid_iou_list, label='Val IoU')\n",
        "plt.title('IoU over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:54:18.836597Z",
          "iopub.execute_input": "2025-09-06T07:54:18.837248Z",
          "iopub.status.idle": "2025-09-06T07:54:19.422828Z",
          "shell.execute_reply.started": "2025-09-06T07:54:18.837219Z",
          "shell.execute_reply": "2025-09-06T07:54:19.421965Z"
        },
        "id": "c6NqFY67ZERx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize model\n",
        "# model = DeepLabV3Plus(num_classes_seg=2, num_classes_cls=2, mode=1).to(DEVICE)\n",
        "\n",
        "# Load best weights\n",
        "model.load_state_dict(torch.load('Seg_RetinaVessel_ColorFundus.pth', map_location=DEVICE))\n",
        "print(\"✅ Loaded best model weights\")\n",
        "\n",
        "# Set to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Create test loader\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
        "\n",
        "# Metrics\n",
        "metrics = [\n",
        "    DiceCoefficient(threshold=0.5),\n",
        "    IoU(threshold=0.5),\n",
        "    AUC(),\n",
        "    Accuracy(threshold=0.5),\n",
        "    Precision(threshold=0.5),\n",
        "    Recall(threshold=0.5),\n",
        "    F1Score(threshold=0.5),\n",
        "]\n",
        "\n",
        "# Initialize accumulators\n",
        "test_stats = {metric.__name__: 0.0 for metric in metrics}\n",
        "test_loss = 0.0\n",
        "total_samples = 0\n",
        "\n",
        "# Evaluation loop\n",
        "with torch.no_grad():\n",
        "    for images, masks in test_loader:\n",
        "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "        preds = model(images)\n",
        "\n",
        "        # Loss\n",
        "        loss = loss_fn(preds, masks)\n",
        "        test_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Metrics\n",
        "        for metric in metrics:\n",
        "            test_stats[metric.__name__] += metric(preds, masks).item() * images.size(0)\n",
        "\n",
        "        total_samples += images.size(0)\n",
        "\n",
        "# Average everything\n",
        "test_loss /= total_samples\n",
        "for key in test_stats:\n",
        "    test_stats[key] /= total_samples\n",
        "\n",
        "# Print results\n",
        "print(\"\\n📊 Test Evaluation Results:\")\n",
        "print(f\"  Loss: {test_loss:.4f}\")\n",
        "for key, value in test_stats.items():\n",
        "    print(f\"  {key}: {value:.4f}\")\n",
        "print(f\"\\nTotal training time: {elapsed_time / 60:.2f} minutes\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:54:19.423564Z",
          "iopub.execute_input": "2025-09-06T07:54:19.42385Z",
          "iopub.status.idle": "2025-09-06T07:54:21.562896Z",
          "shell.execute_reply.started": "2025-09-06T07:54:19.42383Z",
          "shell.execute_reply": "2025-09-06T07:54:21.562053Z"
        },
        "id": "LnxixBcOZERx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # Visualization on test set\n",
        "# test_dataset_vis = MyDataGenerator(test_df, select_class_rgb_values)  # No transforms for visualization\n",
        "# test_loader_vis = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# model.load_state_dict(torch.load(\"/kaggle/working/Combined.pth\"))\n",
        "# model.eval()\n",
        "\n",
        "# sample_preds_folder = 'sample_predictions/'\n",
        "# os.makedirs(sample_preds_folder, exist_ok=True)\n",
        "\n",
        "# max_samples = 20\n",
        "\n",
        "# for idx, (image, gt_mask) in enumerate(test_dataset):\n",
        "#     if idx >= max_samples:\n",
        "#         break\n",
        "\n",
        "#     image_vis = test_dataset_vis[idx][0].astype('uint8')\n",
        "#     true_dims = image_vis.shape[:2]\n",
        "\n",
        "#     x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
        "#     pred_mask = model(x_tensor).detach().squeeze().cpu().numpy()\n",
        "#     pred_mask = np.transpose(pred_mask, (1, 2, 0))\n",
        "\n",
        "#     pred_mask_argmax = np.argmax(pred_mask, axis=-1)\n",
        "#     pred_mask_grayscale = (pred_mask_argmax > 0).astype(np.uint8) * 255\n",
        "\n",
        "#     if pred_mask_grayscale.shape != true_dims:\n",
        "#         pred_mask_grayscale = cv2.resize(pred_mask_grayscale, (true_dims[1], true_dims[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "#     pred_mask_color = colour_code_segmentation(reverse_one_hot(pred_mask), select_class_rgb_values)\n",
        "#     if pred_mask_color.shape[:2] != true_dims:\n",
        "#         pred_mask_color = cv2.resize(pred_mask_color, (true_dims[1], true_dims[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "#     gt_mask = np.transpose(gt_mask, (1, 2, 0))\n",
        "#     gt_mask_argmax = np.argmax(gt_mask, axis=-1)\n",
        "#     gt_mask_grayscale = (gt_mask_argmax > 0).astype(np.uint8) * 255\n",
        "\n",
        "#     if gt_mask_grayscale.shape != true_dims:\n",
        "#         gt_mask_grayscale = cv2.resize(gt_mask_grayscale, (true_dims[1], true_dims[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "#     gt_mask_color = colour_code_segmentation(reverse_one_hot(gt_mask), select_class_rgb_values)\n",
        "#     if gt_mask_color.shape[:2] != true_dims:\n",
        "#         gt_mask_color = cv2.resize(gt_mask_color, (true_dims[1], true_dims[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "#     vis_img = np.hstack([image_vis, gt_mask_color, pred_mask_color])[:, :, ::-1]\n",
        "#     cv2.imwrite(os.path.join(sample_preds_folder, f\"sample_pred_{idx}.png\"), vis_img)\n",
        "\n",
        "#     _, gt_binary = cv2.threshold(gt_mask_grayscale, 127, 1, cv2.THRESH_BINARY)\n",
        "#     _, pred_binary = cv2.threshold(pred_mask_grayscale, 127, 1, cv2.THRESH_BINARY)\n",
        "\n",
        "#     if gt_binary.shape != pred_binary.shape:\n",
        "#         gt_binary = cv2.resize(gt_binary.astype(np.uint8), (pred_binary.shape[1], pred_binary.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "#     tp = np.logical_and(pred_binary, gt_binary)\n",
        "#     tn = np.logical_and(~pred_binary, ~gt_binary)\n",
        "#     fp = np.logical_and(pred_binary, ~gt_binary)\n",
        "#     fn = np.logical_and(~pred_binary, gt_binary)\n",
        "\n",
        "#     vis_overlay = np.zeros((true_dims[0], true_dims[1], 3), dtype=np.uint8)\n",
        "#     vis_overlay[tp] = [255, 0, 0]       # Blue for TP\n",
        "#     vis_overlay[fp & ~tp] = [0, 255, 0] # Green for FP\n",
        "#     vis_overlay[tn & ~fp & ~tp] = [0, 0, 255] # Red for TN\n",
        "#     vis_overlay[fn & ~tp & ~fp] = [0, 255, 255] # Yellow for FN\n",
        "\n",
        "#     cv2.imwrite(os.path.join(sample_preds_folder, f\"tp_tn_fp_fn_{idx}.png\"), vis_overlay)\n",
        "\n",
        "#     vis_overlay_rgb = cv2.cvtColor(vis_overlay, cv2.COLOR_BGR2RGB)\n",
        "#     plt.figure(figsize=(20, 5))\n",
        "\n",
        "#     plt.subplot(1, 4, 1)\n",
        "#     plt.title(\"Original Image\")\n",
        "#     plt.imshow(image_vis)\n",
        "#     plt.axis('off')\n",
        "\n",
        "#     plt.subplot(1, 4, 2)\n",
        "#     plt.title(\"Ground Truth\")\n",
        "#     plt.imshow(gt_mask_color)\n",
        "#     plt.axis('off')\n",
        "\n",
        "#     plt.subplot(1, 4, 3)\n",
        "#     plt.title(\"Predicted Mask\")\n",
        "#     plt.imshow(pred_mask_color)\n",
        "#     plt.axis('off')\n",
        "\n",
        "#     plt.subplot(1, 4, 4)\n",
        "#     plt.title(\"Overlay\")\n",
        "#     plt.imshow(vis_overlay_rgb)\n",
        "#     plt.axis('off')\n",
        "\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "5RlMH2g_4lTX",
        "trusted": true,
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:54:21.563897Z",
          "iopub.execute_input": "2025-09-06T07:54:21.564114Z",
          "iopub.status.idle": "2025-09-06T07:54:21.569272Z",
          "shell.execute_reply.started": "2025-09-06T07:54:21.564095Z",
          "shell.execute_reply": "2025-09-06T07:54:21.568625Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction on Single Image"
      ],
      "metadata": {
        "id": "nRWcn9euZERx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# # Define DEVICE\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# # Define your model (make sure this matches how you defined it before)\n",
        "# model = DeepLabV3Plus(num_num_classes_seg_seg=2, num_num_classes_seg_cls=2, mode=1).to(DEVICE)\n",
        "\n",
        "# # Load weights\n",
        "# weight_path = \"/kaggle/input/cxr-weights/Seg_Lung_CXR.pth\"\n",
        "# model.load_state_dict(torch.load(weight_path, map_location=DEVICE))\n",
        "# model.eval()\n",
        "\n",
        "# print(\"Model loaded and set to evaluation mode.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:54:21.570103Z",
          "iopub.execute_input": "2025-09-06T07:54:21.570406Z",
          "iopub.status.idle": "2025-09-06T07:54:21.588627Z",
          "shell.execute_reply.started": "2025-09-06T07:54:21.570389Z",
          "shell.execute_reply": "2025-09-06T07:54:21.587867Z"
        },
        "id": "VZHKxdUeZERx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # One-hot encoding and decoding\n",
        "# def one_hot_encode(label, label_values):\n",
        "#     semantic_map = []\n",
        "#     for colour in label_values:\n",
        "#         equality = np.equal(label, colour)\n",
        "#         class_map = np.all(equality, axis=-1)\n",
        "#         semantic_map.append(class_map)\n",
        "#     return np.stack(semantic_map, axis=-1)\n",
        "\n",
        "# def reverse_one_hot(image):\n",
        "#     return np.argmax(image, axis=-1)\n",
        "\n",
        "# def colour_code_segmentation(image, label_values):\n",
        "#     colour_codes = np.array(label_values)\n",
        "#     return colour_codes[image.astype(int)]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:54:21.589351Z",
          "iopub.execute_input": "2025-09-06T07:54:21.589535Z",
          "iopub.status.idle": "2025-09-06T07:54:21.605701Z",
          "shell.execute_reply.started": "2025-09-06T07:54:21.589521Z",
          "shell.execute_reply": "2025-09-06T07:54:21.605083Z"
        },
        "id": "65YvB8MyZERx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# def to_tensor(x, **kwargs):\n",
        "#     return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "# def get_preprocessing():\n",
        "#     return album.Compose([\n",
        "#         album.Resize(height=256, width=256, always_apply=True),  # Resize to 256x256\n",
        "#         album.Lambda(image=to_tensor, mask=to_tensor)  # Convert to tensor\n",
        "#     ])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:54:21.606468Z",
          "iopub.execute_input": "2025-09-06T07:54:21.606729Z",
          "iopub.status.idle": "2025-09-06T07:54:21.61947Z",
          "shell.execute_reply.started": "2025-09-06T07:54:21.606704Z",
          "shell.execute_reply": "2025-09-06T07:54:21.61888Z"
        },
        "id": "_0kZxNjtZERy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# def predict_mask_for_single_image(image_path, model, preprocessing_fn, target_size=(256, 256), device='cuda'):\n",
        "#     \"\"\"\n",
        "#     Predicts a binary segmentation mask for a single image.\n",
        "#     Resizes the image in-memory to target_size before processing.\n",
        "#     Returns the original-size image and predicted grayscale mask.\n",
        "#     \"\"\"\n",
        "#     # Load image\n",
        "#     image = cv2.imread(image_path)\n",
        "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#     orig_dims = image.shape[:2]  # HxW (original size)\n",
        "\n",
        "#     # Resize in-memory to model input size\n",
        "#     resized_image = cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "#     # Apply preprocessing\n",
        "#     preprocessed = preprocessing_fn(image=resized_image)\n",
        "#     image_tensor = torch.from_numpy(preprocessed['image']).unsqueeze(0).to(device)\n",
        "\n",
        "#     # Inference\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         output = model(image_tensor).cpu().numpy()\n",
        "\n",
        "#     # Remove batch and transpose to HxWxC\n",
        "#     pred_mask = np.transpose(output[0], (1, 2, 0))\n",
        "\n",
        "#     # Argmax to get predicted class indices\n",
        "#     pred_mask_argmax = np.argmax(pred_mask, axis=-1)\n",
        "\n",
        "#     # Convert to binary grayscale mask (class 1 is foreground)\n",
        "#     pred_mask_grayscale = (pred_mask_argmax > 0).astype(np.uint8) * 255\n",
        "\n",
        "#     # Resize back to original dimensions if needed\n",
        "#     if pred_mask_grayscale.shape != orig_dims:\n",
        "#         pred_mask_grayscale = cv2.resize(\n",
        "#             pred_mask_grayscale,\n",
        "#             (orig_dims[1], orig_dims[0]),  # (width, height)\n",
        "#             interpolation=cv2.INTER_NEAREST\n",
        "#         )\n",
        "\n",
        "#     return image, pred_mask_grayscale"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:54:21.62034Z",
          "iopub.execute_input": "2025-09-06T07:54:21.620616Z",
          "iopub.status.idle": "2025-09-06T07:54:21.633675Z",
          "shell.execute_reply.started": "2025-09-06T07:54:21.620598Z",
          "shell.execute_reply": "2025-09-06T07:54:21.633094Z"
        },
        "id": "7fZlG_fHZERy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Define RGB values for each class\n",
        "# select_class_rgb_values = np.array([\n",
        "#     [0, 0, 0],         # Class 0: Background (Black)\n",
        "#     [255, 255, 255]    # Class 1: Lung / Lesion (White)\n",
        "# ])\n",
        "\n",
        "# model = model.to(DEVICE)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:54:21.63443Z",
          "iopub.execute_input": "2025-09-06T07:54:21.634656Z",
          "iopub.status.idle": "2025-09-06T07:54:21.650571Z",
          "shell.execute_reply.started": "2025-09-06T07:54:21.634631Z",
          "shell.execute_reply": "2025-09-06T07:54:21.649894Z"
        },
        "id": "3Di6pB4kZERy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # Path to your image\n",
        "# single_image_path = \"/kaggle/working/tb-cxr-resized/test/Normal/Normal-1.png\"\n",
        "\n",
        "# # Run prediction\n",
        "# image, pred_grayscale = predict_mask_for_single_image(\n",
        "#     image_path=single_image_path,\n",
        "#     model=model,\n",
        "#     preprocessing_fn=get_preprocessing(),\n",
        "#     device=DEVICE\n",
        "# )\n",
        "\n",
        "# # Visualize\n",
        "# plt.figure(figsize=(10, 5))\n",
        "\n",
        "# plt.subplot(1, 2, 1)\n",
        "# plt.title(\"Input Image\")\n",
        "# plt.imshow(image)\n",
        "# plt.axis('off')\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "# plt.title(\"Predicted Grayscale Mask\")\n",
        "# plt.imshow(pred_grayscale, cmap='gray')\n",
        "# plt.axis('off')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:54:21.651414Z",
          "iopub.execute_input": "2025-09-06T07:54:21.651672Z",
          "iopub.status.idle": "2025-09-06T07:54:21.664509Z",
          "shell.execute_reply.started": "2025-09-06T07:54:21.651656Z",
          "shell.execute_reply": "2025-09-06T07:54:21.663677Z"
        },
        "id": "BzCZYjpSZERy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict mask for dataset"
      ],
      "metadata": {
        "id": "wErsRaGyZERy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# # Define source and target directories\n",
        "# source_root = '/kaggle/working/tb-cxr-resized'\n",
        "# target_root = '/kaggle/working/Segmented_CXR_Masks'\n",
        "\n",
        "# # Counter for visualization every 200 images\n",
        "# counter = 0\n",
        "\n",
        "# # Traverse the dataset structure\n",
        "# for split in ['train', 'test']:\n",
        "#     for label in ['Normal', 'Tuberculosis']:\n",
        "#         source_dir = os.path.join(source_root, split, label)\n",
        "#         target_dir = os.path.join(target_root, split, label)\n",
        "#         os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "#         for filename in tqdm(os.listdir(source_dir), desc=f\"{split}/{label}\"):\n",
        "#             if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "#                 continue\n",
        "\n",
        "#             image_path = os.path.join(source_dir, filename)\n",
        "#             save_path = os.path.join(target_dir, filename)\n",
        "\n",
        "#             try:\n",
        "#                 # Predict mask using your provided function\n",
        "#                 image, pred_grayscale = predict_mask_for_single_image(\n",
        "#                     image_path=image_path,\n",
        "#                     model=model,\n",
        "#                     preprocessing_fn=get_preprocessing(),\n",
        "#                     device=DEVICE\n",
        "#                 )\n",
        "\n",
        "#                 # Ensure pred_grayscale is in [0, 1], then scale to [0, 255]\n",
        "#                 pred_grayscale = np.clip(pred_grayscale, 0, 1)  # safety clamp\n",
        "#                 pred_uint8 = (pred_grayscale * 255).astype(np.uint8)\n",
        "\n",
        "#                 # Squeeze extra dimensions (e.g., (1, H, W, 1) -> (H, W))\n",
        "#                 pred_uint8 = np.squeeze(pred_uint8)\n",
        "\n",
        "#                 # Final sanity check\n",
        "#                 if np.all(pred_uint8 == 0):\n",
        "#                     print(f\"Empty mask generated for {filename}\")\n",
        "\n",
        "#                 # Save mask as grayscale image\n",
        "#                 cv2.imwrite(save_path, pred_uint8)\n",
        "\n",
        "#                 # Visualize every 200th image\n",
        "#                 counter += 1\n",
        "#                 if counter % 200 == 0:\n",
        "#                     plt.figure(figsize=(10, 5))\n",
        "\n",
        "#                     plt.subplot(1, 2, 1)\n",
        "#                     plt.title(\"Input Image\")\n",
        "#                     plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Show RGB\n",
        "#                     plt.axis('off')\n",
        "\n",
        "#                     plt.subplot(1, 2, 2)\n",
        "#                     plt.title(\"Predicted Grayscale Mask\")\n",
        "#                     plt.imshow(pred_uint8, cmap='gray')\n",
        "#                     plt.axis('off')\n",
        "\n",
        "#                     plt.tight_layout()\n",
        "#                     plt.show()\n",
        "\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Failed to process {image_path}: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:54:21.665385Z",
          "iopub.execute_input": "2025-09-06T07:54:21.665609Z",
          "iopub.status.idle": "2025-09-06T07:54:21.681763Z",
          "shell.execute_reply.started": "2025-09-06T07:54:21.665584Z",
          "shell.execute_reply": "2025-09-06T07:54:21.681006Z"
        },
        "id": "-Rw2mHxkZERy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# import os\n",
        "\n",
        "# folder_path = '/kaggle/working/Segmented_CXR'\n",
        "\n",
        "# if os.path.exists(folder_path):\n",
        "#     shutil.rmtree(folder_path)\n",
        "#     print(f\"Deleted the folder and all contents: {folder_path}\")\n",
        "# else:\n",
        "#     print(f\"Folder does not exist: {folder_path}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:54:21.682647Z",
          "iopub.execute_input": "2025-09-06T07:54:21.683493Z",
          "iopub.status.idle": "2025-09-06T07:54:21.699954Z",
          "shell.execute_reply.started": "2025-09-06T07:54:21.683465Z",
          "shell.execute_reply": "2025-09-06T07:54:21.699137Z"
        },
        "id": "_7BT399DZERy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# # Input and output directories\n",
        "# image_root = '/kaggle/working/tb-cxr-resized'\n",
        "# mask_root = '/kaggle/working/Segmented_CXR_Masks'\n",
        "# output_root = '/kaggle/working/Segmented_CXR_Dataset'\n",
        "\n",
        "# global_counter = 0\n",
        "\n",
        "# for split in ['train', 'test']:\n",
        "#     for label in ['Normal', 'Tuberculosis']:\n",
        "#         image_dir = os.path.join(image_root, split, label)\n",
        "#         mask_dir = os.path.join(mask_root, split, label)\n",
        "#         output_dir = os.path.join(output_root, split, label)\n",
        "#         os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "#         for filename in tqdm(os.listdir(image_dir), desc=f\"{split}/{label}\"):\n",
        "#             if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "#                 continue\n",
        "\n",
        "#             image_path = os.path.join(image_dir, filename)\n",
        "#             mask_path = os.path.join(mask_dir, filename)\n",
        "#             save_path = os.path.join(output_dir, filename)\n",
        "\n",
        "#             if not os.path.exists(mask_path):\n",
        "#                 print(f\"Mask not found for: {filename}\")\n",
        "#                 continue\n",
        "\n",
        "#             # Load image and mask\n",
        "#             image = cv2.imread(image_path)\n",
        "#             mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "#             if image is None or mask is None:\n",
        "#                 print(f\"Failed to read image or mask for {filename}\")\n",
        "#                 continue\n",
        "\n",
        "#             # Resize mask to match image shape if needed\n",
        "#             if mask.shape != image.shape[:2]:\n",
        "#                 mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "#             # Convert mask to binary\n",
        "#             _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "#             binary_mask = (binary_mask > 0).astype(np.uint8)\n",
        "\n",
        "#             # Optional: Invert mask if it appears inverted\n",
        "#             # binary_mask = 1 - binary_mask\n",
        "\n",
        "#             # Optional: Clean up small holes using morphological closing\n",
        "#             kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "#             binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "#             # Check if mask is empty\n",
        "#             if np.all(binary_mask == 0):\n",
        "#                 print(f\"Empty mask for {filename}. Skipping.\")\n",
        "#                 continue\n",
        "\n",
        "#             # Apply mask to each channel\n",
        "#             segmented = cv2.bitwise_and(image, image, mask=binary_mask)\n",
        "\n",
        "#             # Save segmented image\n",
        "#             cv2.imwrite(save_path, segmented)\n",
        "\n",
        "#             # Also save binary mask for debugging\n",
        "#             mask_debug_path = save_path.replace(\".jpg\", \"_mask.jpg\").replace(\".jpeg\", \"_mask.jpg\").replace(\".png\", \"_mask.png\")\n",
        "#             cv2.imwrite(mask_debug_path, binary_mask * 255)\n",
        "\n",
        "#             # Visualize every 200th image\n",
        "#             global_counter += 1\n",
        "#             if global_counter % 200 == 0:\n",
        "#                 plt.figure(figsize=(12, 4))\n",
        "\n",
        "#                 plt.subplot(1, 3, 1)\n",
        "#                 plt.title(\"Original Image\")\n",
        "#                 plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "#                 plt.axis('off')\n",
        "\n",
        "#                 plt.subplot(1, 3, 2)\n",
        "#                 plt.title(\"Predicted Mask\")\n",
        "#                 plt.imshow(mask, cmap='gray')\n",
        "#                 plt.axis('off')\n",
        "\n",
        "#                 plt.subplot(1, 3, 3)\n",
        "#                 plt.title(\"Segmented CXR\")\n",
        "#                 plt.imshow(cv2.cvtColor(segmented, cv2.COLOR_BGR2RGB))\n",
        "#                 plt.axis('off')\n",
        "\n",
        "#                 plt.tight_layout()\n",
        "#                 plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:54:21.700896Z",
          "iopub.execute_input": "2025-09-06T07:54:21.701155Z",
          "iopub.status.idle": "2025-09-06T07:54:21.715196Z",
          "shell.execute_reply.started": "2025-09-06T07:54:21.701137Z",
          "shell.execute_reply": "2025-09-06T07:54:21.714401Z"
        },
        "id": "uGD0kumkZERy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# import os\n",
        "\n",
        "# source_dir = '/kaggle/working/Segmented_CXR_Dataset'\n",
        "# zip_path = '/kaggle/working/Segmented_CXR_Dataset.zip'\n",
        "\n",
        "# # Remove existing zip file if it exists (optional safety)\n",
        "# if os.path.exists(zip_path):\n",
        "#     os.remove(zip_path)\n",
        "\n",
        "# # Create zip archive\n",
        "# shutil.make_archive(base_name=zip_path.replace('.zip', ''), format='zip', root_dir=source_dir)\n",
        "\n",
        "# print(f\"✅ Zipped successfully to: {zip_path}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-06T07:54:21.715989Z",
          "iopub.execute_input": "2025-09-06T07:54:21.716295Z",
          "iopub.status.idle": "2025-09-06T07:54:21.734314Z",
          "shell.execute_reply.started": "2025-09-06T07:54:21.716268Z",
          "shell.execute_reply": "2025-09-06T07:54:21.733603Z"
        },
        "id": "1OZUCfM-ZERy"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}